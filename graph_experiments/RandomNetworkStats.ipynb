{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The Function that will Populate a \n",
    "table with statistics of from different null graphs\n",
    "Defined within the range of node/edge combinations \n",
    "predetermined by Preparing_Node_Edge_Restrictions.ipynb\n",
    "\n",
    "Pseudocode:\n",
    "1) Load in the restrictions going to run\n",
    "2) Create a restriction string that\n",
    "ORs all the specific restrictions together\n",
    "--> creates new restriced table\n",
    "3) Create a computed table that pulls from \n",
    "NullModelParamaters_restricted_table:\n",
    "a. Pull down the model paramater\n",
    "b. For n_graph_iterations:\n",
    "    i. Creates the graph with those specified parameters\n",
    "    ii. Runs the certain statistics on it\n",
    "    iii. Writes the statistics to the database\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import graph_statistics_and_simulations as g_stat\n",
    "import graph_generating_functions_library as g_gen\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in and Creating the Restriction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_e_restrictions_data = np.load(\"Viable_node_edge_restrictions.npz\",allow_pickle=True)\n",
    "n_e_restrictions = n_e_restrictions_data[\"saved_node_edge_windows\"]\n",
    "ex_restriction = n_e_restrictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Costructing the large restriction \"\"\"\n",
    "individual_restrictions = [\"(\" + \" AND \".join([\n",
    "    f\"n={j['n_nodes']}\",\n",
    "    f\"edge_average>={j['edge_min']}\",\n",
    "    f\"edge_average<={j['edge_max']}\" + \" )\"\n",
    "]) for j in n_e_restrictions]\n",
    "\n",
    "total_restriction = \" OR \".join(individual_restrictions)\n",
    "total_restriction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create restricted data table\n",
    "\"\"\"\n",
    "\n",
    "import datajoint as dj\n",
    "import numpy as np\n",
    "m65 = dj.create_virtual_module('m65', 'microns_minnie65_01')\n",
    "schema = dj.schema(\"microns_minnie65_01\")\n",
    "dj.config[\"display.limit\"] = 20\n",
    "dj.config['enable_python_native_blobs'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restricted_null_models = m65.NullModelParameters & total_restriction\n",
    "len(m65.NullModelParameters()),len(restricted_null_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figuring Out what statistics to run and function to run them all\n",
    "# (Will just store them as blobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_functions=[k for k in dir(g_stat) if \"directional\" in dir(getattr(g_stat,k))]\n",
    "list_function_not_run = ['smallest_laplacian_eigen_value',\n",
    "                        'node_connectivity',\n",
    "                        \"average_degree_connectivity\",\n",
    "                        \"random_degree_site_percolation\",\n",
    "                        \"pandemic_beta\",\n",
    "                        \"power_law_alpha_sigma\"]\n",
    "\n",
    "for fn in list_function_not_run:\n",
    "    list_of_functions.remove(fn)\n",
    "list_of_functions = np.sort(list_of_functions)\n",
    "\n",
    "functions_list = [getattr(g_stat,k) for k in list_of_functions]\n",
    "functions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_graph_experiment(graph_function,\n",
    "                               functions_list,\n",
    "                               graph_parameters,\n",
    "                               print_flag=False,\n",
    "                               attr=[]):\n",
    "    global_start = time.time()\n",
    "    \n",
    "    #gets the names of all of the stats going to run\n",
    "    stats_list = [k.__name__ for k in functions_list]\n",
    "    \n",
    "    total_stats_list = dict([(k,[]) for k in stats_list])\n",
    "    if print_flag:\n",
    "        print(f\"graph_function = {graph_function}\")\n",
    "    graph_type = graph_function.__name__\n",
    "    \n",
    "    \n",
    "    data_structure = dict()\n",
    "    \n",
    "    loop_start = time.time()\n",
    "    graph_args = graph_parameters\n",
    "    \n",
    "    #creating the graph with randomize locations\n",
    "    creation_time = time.time()\n",
    "    max_graph_creation_tries = 10\n",
    "    creation_flag = False\n",
    "    for i in range(0,max_graph_creation_tries):\n",
    "        try:\n",
    "            if print_flag:\n",
    "                print(\"graph_args = \" + str(graph_parameters))\n",
    "            G = graph_function(**graph_parameters)\n",
    "            creation_flag = True\n",
    "            break\n",
    "        except:\n",
    "            if print_flag:\n",
    "                print(f\"Graph creationg Failed, starting try #{i + 1}\")\n",
    "\n",
    "    if not creation_flag:\n",
    "        raise Exception(f\"Couldn't build graph after {max_graph_creation_tries} tries\")\n",
    "\n",
    "\n",
    "    if print_flag:\n",
    "        print(f\"   Graph Creation time = {time.time() - creation_time}\")\n",
    "\n",
    "    full_graph_name = str(graph_type) + \":\"\n",
    "    for k,v in graph_parameters.items():\n",
    "        if type(v) == float:\n",
    "            full_graph_name += f\"_{k}={v:.2f}\"\n",
    "        else:\n",
    "            full_graph_name += f\"_{k}={v}\"\n",
    "    for at in attr:\n",
    "        full_graph_name += \"_\" + str(at)\n",
    "        \n",
    "    \n",
    "    data_structure = dict()\n",
    "    data_structure[\"graph_name\"] = full_graph_name\n",
    "    data_structure[\"graph_type\"] = graph_type\n",
    "    data_structure[\"n_nodes\"] = len(G.nodes)\n",
    "    data_structure[\"n_edges\"] = len(G.edges())\n",
    "    for k,v in graph_parameters.items():\n",
    "        data_structure[k] = v\n",
    "        \n",
    "    stats_dict_update = g_stat.graph_statistics_vp2(G,functions_list,\n",
    "                                             undirected_flag = False,\n",
    "                                             time_print_flag=print_flag,\n",
    "                                             output_print_flag = print_flag)\n",
    "    data_structure.update(stats_dict_update)\n",
    "    \n",
    "    if print_flag:\n",
    "        print(f\"    Total time for iteration = {time.time() - global_start}\")\n",
    "        \n",
    "    return data_structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Running Statistics on One Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_graph = (m65.NullModelParameters & \"graph_hash=94759\").fetch1()\n",
    "example_graph\n",
    "\n",
    "#getting the right graph function \n",
    "total_functions_modules = [z for z in dir(g_gen) if \n",
    "                           type(getattr(g_gen,z)) == type(np.sum)]\n",
    "matching_function = [getattr(g_gen,j) for j in total_functions_modules if \n",
    "                               getattr(g_gen,j).__name__ == example_graph[\"graph_name\"]]\n",
    "\n",
    "if len(matching_function) != 1:\n",
    "    print(\"Number of matching functions is not exactly one\")\n",
    "else:\n",
    "    g_func = matching_function[0]\n",
    "    \n",
    "#getting the right parameters\n",
    "param_exclusion_list = [\"graph_hash\",\"graph_name\",\"edge_average\",\"edge_deviation\"]\n",
    "param_dict = dict([(k,v) for k,v in example_graph.items() if \n",
    "                  ((v != None and v != np.nan) and\n",
    "                  (k not in param_exclusion_list))])\n",
    "param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_iterations = 2\n",
    "# start_time = time.time()\n",
    "# total_insert_dict = []\n",
    "# for i in range(0,n_iterations):\n",
    "#     returned_dict = run_single_graph_experiment(graph_function=g_func,\n",
    "#                                functions_list=functions_list,\n",
    "#                                graph_parameters=param_dict,\n",
    "#                                print_flag=True)\n",
    "#     insert_dict = dict(graph_name=returned_dict[\"graph_name\"],\n",
    "#                    run_number = i,\n",
    "#                   graph_type =returned_dict[\"graph_type\"],\n",
    "#                   n_nodes=returned_dict[\"n_nodes\"],\n",
    "#                   n_edges=returned_dict[\"n_edges\"],\n",
    "#                   statistics=returned_dict)\n",
    "#     total_insert_dict.append(insert_dict)\n",
    "    \n",
    "# total_insert_dict\n",
    "# print(f\"Total time = {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomNetworkStats.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_stat = (RandomNetworkStats() & \"graph_hash=1577292\" & \"run_number=0\").fetch1(\"statistics\")\n",
    "# my_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations = 50\n",
    "@schema\n",
    "class RandomNetworkStats(dj.Computed):\n",
    "    definition=\"\"\"\n",
    "    -> m65.NullModelParameters\n",
    "    graph_name: char(120)  # the name of the run with all of the parameters\n",
    "    run_number: int unsigned #the number run for this graph\n",
    "    ---\n",
    "    graph_type : char(60)  # The exact type of graph run\n",
    "    n_nodes:          int unsigned      # number of nodes\n",
    "    n_edges:          int unsigned      # number of edges in graph\n",
    "    statistics:       longblob  #stores all of the statistics in the run\n",
    "    \"\"\"\n",
    "\n",
    "    key_source = m65.NullModelParameters & total_restriction\n",
    "    \n",
    "    def make(self,key):\n",
    "        \n",
    "        global_time = time.time()\n",
    "        example_graph = (m65.NullModelParameters & key).fetch1()\n",
    "        print(f\"\\n\\n -- Working on {example_graph} -- \")\n",
    "\n",
    "        #getting the right graph function \n",
    "        total_functions_modules = [z for z in dir(g_gen) if \n",
    "                                   type(getattr(g_gen,z)) == type(np.sum)]\n",
    "        matching_function = [getattr(g_gen,j) for j in total_functions_modules if \n",
    "                                       getattr(g_gen,j).__name__ == example_graph[\"graph_name\"]]\n",
    "\n",
    "        if len(matching_function) != 1:\n",
    "            raise Exception(\"Number of matching functions is not exactly one\")\n",
    "            \n",
    "        else:\n",
    "            g_func = matching_function[0]\n",
    "\n",
    "        #getting the right parameters\n",
    "        param_exclusion_list = [\"graph_hash\",\"graph_name\",\"edge_average\",\"edge_deviation\"]\n",
    "        param_dict = dict([(k,v) for k,v in example_graph.items() if \n",
    "                          ((v != None and v != np.nan) and\n",
    "                          (k not in param_exclusion_list))])\n",
    "        \n",
    "        \n",
    "        start_time = time.time()\n",
    "        total_insert_dict = []\n",
    "        for i in range(0,n_iterations):\n",
    "            returned_dict = run_single_graph_experiment(graph_function=g_func,\n",
    "                                       functions_list=functions_list,\n",
    "                                       graph_parameters=param_dict,\n",
    "                                       print_flag=False)\n",
    "            insert_dict = dict(graph_hash=key[\"graph_hash\"],\n",
    "                graph_name=returned_dict[\"graph_name\"],\n",
    "                           run_number = i,\n",
    "                          graph_type =returned_dict[\"graph_type\"],\n",
    "                          n_nodes=returned_dict[\"n_nodes\"],\n",
    "                          n_edges=returned_dict[\"n_edges\"],\n",
    "                          statistics=returned_dict)\n",
    "            total_insert_dict.append(insert_dict)\n",
    "        \n",
    "        print(f\"Total time for {n_iterations} iterations: {time.time() - global_time}\")\n",
    "        #now do the insert\n",
    "        self.insert(total_insert_dict,skip_duplicates=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(schema.jobs & \"table_name='__random_network_stats'\").delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "RandomNetworkStats.populate(reserve_jobs=True)\n",
    "print(f\"Total time for RandomNetworkStats populate = {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
